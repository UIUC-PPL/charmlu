mainmodule lu {
  readonly CProxy_Main mainProxy;
  readonly CProxy_LUBlk luArrProxy;

  readonly int gMatSize;
  readonly ComlibInstanceHandle multicastStats[4];
  readonly int traceTrailingUpdate;
  readonly int traceComputeU;
  readonly int traceComputeL;
  readonly int traceSolveLocalLU;
  readonly int doPrioritize;
//  readonly int memThreshold;

  message blkMsg {
    double data[];
  };

  mainchare Main {
    entry Main(CkArgMsg *m);
    entry void finishInit();
    entry void continueIter();
    entry void arrayIsCreated(CkReductionMsg *);
    entry void outputStats();
    entry void terminateProg();
    entry void done(pathInformationMsg *m);
    entry void iterationCompleted();
  };

  array [2D] LUBlk {
    entry LUBlk(void);
    entry void init(int whichMulticastStrategy, int, int, int memThreshold);
    entry void initVec(int size, double bvec[size]);

    entry void run()
    {
	for (internalStep = 0;
	     internalStep < min(thisIndex.x, thisIndex.y);
	     internalStep++) {
	    overlap {
		when recvL[internalStep](blkMsg *mL) atomic
		{ CmiReference(UsrToEnv(mL)); L = mL; }
		when recvU[internalStep](blkMsg *mU) atomic
		{ CmiReference(UsrToEnv(mU)); U = mU; }
	    }
	    atomic {
		// Let the scheduler do this sometime later
		thisProxy(thisIndex.x, thisIndex.y)
		    .processTrailingUpdate(internalStep);
	    }
	    when processTrailingUpdate[internalStep](int step) atomic {
		updateMatrix(L, U);
		CmiFree(UsrToEnv(L)); CmiFree(UsrToEnv(U));
	    }
	}

	if (thisIndex.x == thisIndex.y) atomic {
		ckout << "Block " << thisIndex.x << " queueing local LU" << endl;
		thisProxy(thisIndex.x, thisIndex.y).processLocalLU(0);
	}
	else if (thisIndex.x < thisIndex.y)
	    when recvL[internalStep](blkMsg *mL) atomic {
		CmiReference(UsrToEnv(mL)); L = mL;
		thisProxy(thisIndex.x, thisIndex.y).processComputeU(0);
	}
	else
	    when recvU[internalStep](blkMsg *mU) atomic {
		CmiReference(UsrToEnv(mU)); U = mU;
		thisProxy(thisIndex.x, thisIndex.y).processComputeL(0);
	}
    };

    entry /*[nokeep]*/ void recvL(blkMsg *);
    entry /*[nokeep]*/ void recvU(blkMsg *);

    /// These process* entry methods are invoked locally with varying
    /// priorities, to let the scheduler decide when the work they
    /// represent (the bulk of the computation) should execute.

    entry [memcritical] void processTrailingUpdate(int ignoredParam);
    entry void processLocalLU(int ignoredParam);

    // These two free buffered messages, but don't really reduce
    // memory pressure, because they generate multicasts along the
    // way. Hence, not marked [memcritical]
    entry void processComputeL(int ignoredParam);
    entry void processComputeU(int ignoredParam);


    entry void solve(bool backward, int size, double d[size]);
    entry void forwardSolve(int size, double d[size]);
    entry void diagForwardSolve(int size, double d[size]);

    entry void flushLogs();
    entry void print();
  };        	

  group BlockCyclicMap : CkArrayMap{
    entry BlockCyclicMap();
  };

  group LUSnakeMap : CkArrayMap{
    entry LUSnakeMap(int, int);
  };

  group LUBalancedSnakeMap : CkArrayMap{
    entry LUBalancedSnakeMap(int, int);
  };

  group LUBalancedSnakeMap2 : CkArrayMap{
    entry LUBalancedSnakeMap2(int, int);
  };

};
