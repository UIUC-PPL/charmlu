mainmodule lu {
  readonly CProxy_Main mainProxy;
  readonly CProxy_LUBlk luArrProxy;

  readonly int gMatSize;
  readonly ComlibInstanceHandle multicastStats[4];
  readonly int traceTrailingUpdate;
  readonly int traceComputeU;
  readonly int traceComputeL;
  readonly int traceSolveLocalLU;
  readonly int doPrioritize;
//  readonly int memThreshold;

  message blkMsg {
    double data[];
  };

  mainchare Main {
    entry Main(CkArgMsg *m);
    entry void finishInit();
    entry void continueIter();
    entry void arrayIsCreated(CkReductionMsg *);
    entry void outputStats();
    entry void terminateProg(CkReductionMsg *);
    entry void done(pathInformationMsg *m);
    entry void iterationCompleted();
  };

  array [2D] LUBlk {
    entry LUBlk(void);
    entry void init(int whichMulticastStrategy, int, int, int memThreshold);
    entry void initVec(int size, double bvec[size]);
    entry void startValidation();
    entry [nokeep] void recvXvec(int size, double xvec[size]);
    entry void sumBvec(int size, double partial_b[size]);

    entry void factor()
    {
	for (internalStep = 0;
	     internalStep < min(thisIndex.x, thisIndex.y);
	     internalStep++) {
            for (int i = 0; i < BLKSIZE; i++) {
              when doPivot[internalStep](int row1, int row2) atomic {  
                swap(row1, row2);
              }
            }
	    overlap {
		when recvL[internalStep](blkMsg *mL) atomic
		{ CmiReference(UsrToEnv(mL)); L = mL; }
		when recvU[internalStep](blkMsg *mU) atomic
		{ CmiReference(UsrToEnv(mU)); U = mU; }
	    }
	    atomic {
		// Schedule the trailing update for sometime later
		thisProxy(thisIndex.x, thisIndex.y)
		    .processTrailingUpdate(internalStep);
	    }
	    when processTrailingUpdate[internalStep](int step) atomic {
		updateMatrix(L, U);
		CmiFree(UsrToEnv(L)); CmiFree(UsrToEnv(U));
	    }
	}

	if (thisIndex.x == thisIndex.y) atomic {
		ckout << "Block " << thisIndex.x << " queueing local LU" << endl;
		//thisProxy(thisIndex.x, thisIndex.y).processLocalLU(0);
                thisProxy(thisIndex.x, thisIndex.y).processLU();
	} else if (thisIndex.x < thisIndex.y)
	    when recvL[internalStep](blkMsg *mL) atomic {
		CmiReference(UsrToEnv(mL)); L = mL;
		thisProxy(thisIndex.x, thisIndex.y).processComputeU(0);
	} else {
                for (int col = 0; col < BLKSIZE; col++) {
                  atomic "computeMax" {
                    double maxval = LU[getIndex(0, col)];
                    int maxrow = 0;
                    
                    locval l = findLocVal(1, col, maxval, maxrow);

                    // TODO: compute colSection for the section reduction
                    // should be from [thisIndex.x, numBlks], needs to call colMax
                    // CkGetSectionInfo();
                    // colSection->contribute(sizeof(locval), &l, maxLocVal, colMax);
                  }
                  when doPivot(int row1, int row2) atomic {
                    // Assume that row2 is always the non-diagonal row
                    // and that LU is row-major
                    if (row2 / BLKSIZE == thisIndex.x) {
                      thisProxy(thisIndex.y, thisIndex.y).
                                sendPivotData(BLKSIZE, &LU[getIndex(row2 % BLKSIZE, 0)]);
                      when sendPivotData(int size, double* data) atomic {
                        applySwap(row1 % BLKSIZE, data);
                      }
                    }
                  }
                  when sendUSegment(int size, double* usegment) {
                    // Just the first column
                    computeMultipliers();
                    
                    // Options: this SDAG code (or something like it)

                    /*
                    // Somehow this needs to be overlapped with the maxCol sends

                    for (int innercol = 1; innercol < BLKSIZE; innercol++) {
                      thisProxy(thisIndex.x, thisIndex.y).updateRemCols(innercol);
                    }
                    
                    when updateRemCols(int icol) atomic {
                      doUpdate();
                    }
                    */
                    
                    // Or: DGEMM
                    updateAllCols();
                  }

	    /*when recvU[internalStep](blkMsg *mU) atomic {
		CmiReference(UsrToEnv(mU)); U = mU;
		thisProxy(thisIndex.x, thisIndex.y).processComputeL(0);
	    }*/
	}

        multicastRecvL();
    };

    entry void processLU()
    {
	for (int col = 0; col < BLKSIZE; ++col) {
	    when colMax(CkReductionMsg *m) atomic {
		locval &remoteL = *(locval *)(m->getData());
                locval l = findLocVal(col, col, remoteL.val, remoteL.loc);
		if (l.loc / BLKSIZE != thisIndex.x) {
                    atomic {
                      thisProxy.doPivot(l.loc, col + BLKSIZE * thisIndex.y);
                    }
                    when doPivot(int row1, int row2) atomic {
                      // Data must be row-major for marshalling to work
                      thisProxy(l.loc / BLKSIZE, thisIndex.y).
                                sendPivotData(BLKSIZE, &LU[getIndex(col, 0)]);
                    }
                    when sendPivotData(int size, double* data) atomic {
                      applySwap(col, data);
                    }
		} else {
                  swapLocal(l.loc, col);
                }
                
                CProxySection_LUBlk oneCol = CProxySection_LUBlk::ckNew(thisArrayID, thisIndex.x+1, numBlks-1, 1, thisIndex.y, thisIndex.y, 1);
                oneCol.sendUSegment(BLKSIZE, &LU[getIndex(col, 0)]);
                
                localRowDecompose();
	    }
	}

        multicastRecvL();
    };

    // These entry methods are the targets of the row- and column-wise
    // multicasts each block makes.
    //
    // These methods reference but will not modify the messages
    // delivered to them. Thus, we can use the [nokeep] annotation to
    // tell the runtime that it can safely deliver the same message
    // instance to every object on a processor, rather than making a
    // separate copy for each object.
    entry [nokeep] void recvL(blkMsg *);
    entry [nokeep] void recvU(blkMsg *);

    // These process* entry methods are invoked locally by each block
    // on itself with varying priorities, to let the scheduler decide
    // when the work they represent (the bulk of the computation)
    // should execute.
    //
    // When a block computes a trailing update, it no longer needs to
    // retain the incoming data from the corresponding row and column
    // updates. The [memcritical] annotation tells the runtime that it
    // should schedule invocations of this entry method when it is in
    // a memory critical (i.e. over threshold) condition, so that
    // retained messages can be freed.
    entry [memcritical] void processTrailingUpdate(int ignoredParam);
    entry void processLocalLU(int ignoredParam);
    // These two free buffered messages, but don't really reduce
    // memory pressure, because they generate multicasts along the
    // way. Hence, they're not marked [memcritical].
    entry void processComputeL(int ignoredParam);
    entry void processComputeU(int ignoredParam);


    entry void solve(bool backward, int size, double d[size]);
    entry void forwardSolve(int size, double d[size]);
    entry void diagForwardSolve(int size, double d[size]);
    entry void backwardSolve(int size, double d[size]);
    entry void diagBackwardSolve(int size, double d[size]);

    entry void flushLogs();
    entry void print();
  };        	

  group BlockCyclicMap : CkArrayMap{
    entry BlockCyclicMap();
  };

  group LUSnakeMap : CkArrayMap{
    entry LUSnakeMap(int, int);
  };

  group LUBalancedSnakeMap : CkArrayMap{
    entry LUBalancedSnakeMap(int, int);
  };

  group LUBalancedSnakeMap2 : CkArrayMap{
    entry LUBalancedSnakeMap2(int, int);
  };

};
