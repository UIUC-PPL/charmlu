mainmodule lu {
  readonly CProxy_Main mainProxy;
  readonly CProxy_LUBlk luArrProxy;

  readonly int gMatSize;
  readonly ComlibInstanceHandle multicastStats[4];
  readonly int traceTrailingUpdate;
  readonly int traceComputeU;
  readonly int traceComputeL;
  readonly int traceSolveLocalLU;
  readonly int doPrioritize;
//  readonly int memThreshold;

  message blkMsg {
    double data[];
  };

  mainchare Main {
    entry Main(CkArgMsg *m);
    entry void finishInit();
    entry void continueIter();
    entry void arrayIsCreated(CkReductionMsg *);
    entry void outputStats();
    entry void terminateProg(CkReductionMsg *);
    entry void done(pathInformationMsg *m);
    entry void iterationCompleted();
  };

  array [2D] LUBlk {
    entry LUBlk(void);
    entry void init(int whichMulticastStrategy, int, int, int memThreshold);
    entry void initVec(int size, double bvec[size]);
    entry void startValidation();
    entry [nokeep] void recvXvec(int size, double xvec[size]);
    entry void sumBvec(int size, double partial_b[size]);

    entry void colMax(CkReductionMsg *m);
    entry void sendPivotData(int rowIndex, int size, double data[size]);
    entry void doPivot(int internalStep, int row1, int row2);
    entry void sendUSegment(int size, double usegment[size]);

    entry void factor() {
      for (internalStep = 0;
           internalStep < min(thisIndex.x, thisIndex.y);
           internalStep++) {
        for (pivotBlk = 0; pivotBlk < BLKSIZE; pivotBlk++) {
          when doPivot[internalStep](int step, int row1, int row2) atomic {
            row1Index = row1 / BLKSIZE;
            row2Index = row2 / BLKSIZE;
            localRow1 = row1 % BLKSIZE;
            localRow2 = row2 % BLKSIZE;
            remoteSwap = false;

            if (row1Index == thisIndex.x &&
                row2Index == thisIndex.y) {
              swapLocal(localRow1, localRow2);
            } else if (row1Index == thisIndex.x) {
              thisLocalRow = localRow1;
              otherRowIndex = row1Index;
              globalThisRow = row2;
              globalOtherRow = row1;
              remoteSwap = true;
            } else if (row2Index == thisIndex.x) {
              thisLocalRow = localRow2;
              otherRowIndex = row2Index;
              globalThisRow = row1;
              globalOtherRow = row2;
              remoteSwap = true;
            }
          }
          if (remoteSwap) {
            atomic {
              thisProxy(otherRowIndex, thisIndex.y)
                        .sendPivotData(globalOtherRow, BLKSIZE, &LU[getIndex(thisLocalRow, 0)]);
            }
            when sendPivotData[globalThisRow](int index, int size, double data[size]) atomic {
		applySwap(thisLocalRow, 0, data);
            }
          }
        }
        overlap {
          when recvL[internalStep](blkMsg *mL) atomic
            { CmiReference(UsrToEnv(mL)); L = mL; }
          when recvU[internalStep](blkMsg *mU) atomic
            { CmiReference(UsrToEnv(mU)); U = mU; }
        }
        atomic {
          // Schedule the trailing update for sometime later
          thisProxy(thisIndex.x, thisIndex.y).processTrailingUpdate(internalStep);
        }
        when processTrailingUpdate[internalStep](int step) atomic {
          updateMatrix(L, U);
          CmiFree(UsrToEnv(L)); CmiFree(UsrToEnv(U));
        }
      }

      if (thisIndex.x == thisIndex.y) atomic {
        ckout << "Block " << thisIndex.x << " queueing local LU" << endl;
        //thisProxy(thisIndex.x, thisIndex.y).processLocalLU(0);
        thisProxy(thisIndex.x, thisIndex.y).processLU();
      } else if (thisIndex.x < thisIndex.y)
        when recvL[internalStep](blkMsg *mL) atomic {
          CmiReference(UsrToEnv(mL)); L = mL;
          thisProxy(thisIndex.x, thisIndex.y).processComputeU(0);
      } else {
        for (activeCol = 0; activeCol < BLKSIZE; activeCol++) {
          atomic "computeMax" {
            double maxval = LU[getIndex(0, activeCol)];
            int maxrow = 0;

            locval l = findLocVal(1, activeCol, maxval, maxrow);

            // Contribute to a reduction along the pivot section
            // The pivot section includes all sub-diagonal chares
            // along the active column of the chare array

	    CkCallback maxcb(CkIndex_LUBlk::colMax(0),
			     thisProxy(activeCol, activeCol));

            // TODO: compute colSection for the section reduction
            // should be from [thisIndex.x, numBlks], needs to call colMax
            // CkGetSectionInfo();
            colSection->contribute(sizeof(locval), &l, maxLocVal, maxcb);
          }
          when doPivot[internalStep](int step, int row1, int row2) {
            // Assume that row2 is always the non-diagonal row
            // and that LU is row-major
            if (row2 / BLKSIZE == thisIndex.x) {
              atomic {
                thisProxy(thisIndex.y, thisIndex.y)
                          .sendPivotData(row2, BLKSIZE, &LU[getIndex(row2 % BLKSIZE, 0)]);
              }
              when sendPivotData[row1](int rowIndex, int size, double data[size]) atomic {
		  applySwap(row2 % BLKSIZE, 0, data);
              }
            }
          }
          when sendUSegment(int size, double usegment[size]) atomic {
            // computer the multipliers using the diagonal element
            //usegment[0] should contain the diagonal element
            computeMultipliers(usegment[0], 0, activeCol);

            // Options: this SDAG code (or something like it)
            // Somehow this needs to be overlapped with the maxCol sends

            //for (int innercol = 1; innercol < BLKSIZE; innercol++) {
            //thisProxy(thisIndex.x, thisIndex.y).updateRemCols(innercol);
            //}

            //when updateRemCols(int icol) atomic {
            //doUpdate();
            //}

            // Or: DGEMM
            updateAllCols(activeCol, usegment);
          }
        }
        atomic {
          multicastRecvL();
        }
      }
    };

    entry void processLU() {
      for (activeCol = 0; activeCol < BLKSIZE; ++activeCol) {
        when colMax(CkReductionMsg *m) atomic {
          locval &remoteL = *(locval *)(m->getData());
          l = findLocVal(activeCol, activeCol, remoteL.val, remoteL.loc);
        }
        atomic {
          // Builds a section that addresses every block on and below the current
          // diagonal element's row
          CProxySection_LUBlk below = CProxySection_LUBlk::ckNew(thisArrayID, thisIndex.x, numBlks-1, 1, 0, numBlks-1, 1);
          
          below.doPivot(internalStep, l.loc, activeCol + BLKSIZE * thisIndex.y);
        }
        if (l.loc / BLKSIZE != thisIndex.x) {
          when doPivot[internalStep](int step, int row1, int row2) atomic {
            // Data must be row-major for marshalling to work
            thisProxy(row1 / BLKSIZE, thisIndex.y)
                      .sendPivotData(row1, BLKSIZE, &LU[getIndex(row1 % BLKSIZE, 0)]);
          }
          when sendPivotData[activeCol + BLKSIZE * thisIndex.y](int rowIndex, int size, 
                                                                double data[size]) atomic {
	      applySwap(activeCol, 0, data);
          }
        } else atomic {
          swapLocal(l.loc, activeCol);
        }
        atomic {
          CProxySection_LUBlk oneCol = CProxySection_LUBlk::ckNew(thisArrayID, thisIndex.x+1, numBlks-1, 1, thisIndex.y, thisIndex.y, 1);
          oneCol.sendUSegment(BLKSIZE - activeCol, &LU[getIndex(activeCol, activeCol)]);

          diagonalUpdate(activeCol);
        }
      }
      atomic {
        multicastRecvL();
      }
    };

    // These entry methods are the targets of the row- and column-wise
    // multicasts each block makes.
    //
    // These methods reference but will not modify the messages
    // delivered to them. Thus, we can use the [nokeep] annotation to
    // tell the runtime that it can safely deliver the same message
    // instance to every object on a processor, rather than making a
    // separate copy for each object.
    entry [nokeep] void recvL(blkMsg *);
    entry [nokeep] void recvU(blkMsg *);

    // These process* entry methods are invoked locally by each block
    // on itself with varying priorities, to let the scheduler decide
    // when the work they represent (the bulk of the computation)
    // should execute.
    //
    // When a block computes a trailing update, it no longer needs to
    // retain the incoming data from the corresponding row and column
    // updates. The [memcritical] annotation tells the runtime that it
    // should schedule invocations of this entry method when it is in
    // a memory critical (i.e. over threshold) condition, so that
    // retained messages can be freed.
    entry [memcritical] void processTrailingUpdate(int ignoredParam);
    entry void processLocalLU(int ignoredParam);
    // These two free buffered messages, but don't really reduce
    // memory pressure, because they generate multicasts along the
    // way. Hence, they're not marked [memcritical].
    entry void processComputeL(int ignoredParam);
    entry void processComputeU(int ignoredParam);


    entry void solve(bool backward, int size, double d[size]);
    entry void forwardSolve(int size, double d[size]);
    entry void diagForwardSolve(int size, double d[size]);
    entry void backwardSolve(int size, double d[size]);
    entry void diagBackwardSolve(int size, double d[size]);

    entry void flushLogs();
    entry void print();
  };            

  group BlockCyclicMap : CkArrayMap{
    entry BlockCyclicMap();
  };

  group LUSnakeMap : CkArrayMap{
    entry LUSnakeMap(int, int);
  };

  group LUBalancedSnakeMap : CkArrayMap{
    entry LUBalancedSnakeMap(int, int);
  };

  group LUBalancedSnakeMap2 : CkArrayMap{
    entry LUBalancedSnakeMap2(int, int);
  };

};
